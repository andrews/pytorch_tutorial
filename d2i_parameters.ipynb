{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFUKMHjwaXyLGdYIZmsaTI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrews/pytorch_tutorials/blob/main/d2i_parameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(From the text)\n",
        "\n",
        "Most of the time, we will be able to ignore the nitty-gritty details of how parameters are declared and manipulated, relying on deep learning frameworks to do the heavy lifting. However, when we move away from stacked architectures with standard layers, we will sometimes need to get into the weeds of declaring and manipulating parameters. In this section, we cover the following:\n",
        "\n",
        "Accessing parameters for debugging, diagnostics, and visualizations.\n",
        "\n",
        "Sharing parameters across different model components."
      ],
      "metadata": {
        "id": "B-so72cMevqj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R07c6PmFdXm3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(nn.LazyLinear(8),\n",
        "                    nn.ReLU(),\n",
        "                    nn.LazyLinear(1))\n",
        "\n",
        "X = torch.rand(size=(2, 4))\n",
        "net(X).shape\n",
        "# batch size of 2, 1 output feature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMuG4P4cfCK8",
        "outputId": "15b33b20-362e-4968-fd08-def8255f1dc9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X) # 2 rows 4 cols OR batch size 2 and 4 features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRxdOmx_fQGm",
        "outputId": "0bb087e3-edc7-4e0b-d1f0-c9a093206abe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3860, 0.8639, 0.2895, 0.1375],\n",
            "        [0.2288, 0.2885, 0.3286, 0.4527]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameter Access"
      ],
      "metadata": {
        "id": "AU3C3VGzf2Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in Sequential class, layers can be accessed like a list\n",
        "net[2].state_dict() # output layer.\n",
        "# 8 because first layer is 8, then relu keeps it 8, then 8 weights in output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-NFSWn-f5sY",
        "outputId": "e27c4c85-8b10-47ec-e521-60fe5dc11ed2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[-0.3389, -0.2414,  0.1266, -0.3465, -0.0219, -0.2282, -0.2693, -0.0183]])),\n",
              "             ('bias', tensor([-0.2206]))])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net[2].bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DqFAjcYhVky",
        "outputId": "fc05802a-0e0d-4dbe-dec3-6811abc3e7ae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.2206], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(net[2].bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i189-o3WiTiA",
        "outputId": "ecbb98f1-2c61-486d-f66d-6f9c449c6d1a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.nn.parameter.Parameter"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net[2].bias.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFwkTKfsicl1",
        "outputId": "e17a5566-0440-4151-e168-df5e370f9225"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2206])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# no gradient since we did not invoke back propagation\n",
        "net[2].weight.grad == None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odXdP1ftigww",
        "outputId": "7c89c15f-f5f3-4624-b41a-67b9949bc6b3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# access all parameters\n",
        "[(name, param.shape) for name, param in net.named_parameters()]\n",
        "# here the sizes are different from [batch size, num of features]\n",
        "# it's [output features, input features]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY8ODhAYk0iK",
        "outputId": "85e332c6-8e27-4fd2-c87e-a743dc5a0d7e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('0.weight', torch.Size([8, 4])),\n",
              " ('0.bias', torch.Size([8])),\n",
              " ('2.weight', torch.Size([1, 8])),\n",
              " ('2.bias', torch.Size([1]))]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# share parameters across multiple layers\n",
        "# give the shared layer a name\n",
        "shared = nn.LazyLinear(8)\n",
        "net = nn.Sequential(nn.LazyLinear(8), nn.ReLU(),\n",
        "                    shared, nn.ReLU(),\n",
        "                    shared, nn.ReLU(),\n",
        "                    nn.LazyLinear(1))\n",
        "\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdeO_a0UnICV",
        "outputId": "eac00587-598c-4016-b990-f6a2793fdcc5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1818],\n",
              "        [-0.1781]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check whether the parameters are the same\n",
        "print(net[2].weight.data[0] == net[4].weight.data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0d5q2Tbo3Mg",
        "outputId": "b950fae4-9887-486f-c6e0-4d0d10186c88"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True, True, True, True, True, True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net[2].weight.data[0, 0] = 100\n",
        "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
        "# same object in memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71MowUIOo_Wl",
        "outputId": "1b4f6b6d-dcb1-41df-a9dc-4e37e84d7c2f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True, True, True, True, True, True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(From the text)\n",
        "\n",
        "You might wonder, when parameters are tied what happens to the gradients? Since the model parameters contain gradients, the gradients of the second hidden layer and the third hidden layer are added together during backpropagation."
      ],
      "metadata": {
        "id": "I2nM-DsRrnP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameter Initialization\n",
        "\n",
        "Not just randomly initializing parameters. Looks like there are different schemas for initializing. Can possibly run into vanishing and exploding gradients. More discussion [here](https://d2l.ai/chapter_multilayer-perceptrons/numerical-stability-and-init.html#sec-numerical-stability)"
      ],
      "metadata": {
        "id": "Pq9KlyEFvfMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "tgQIaJHnvhMg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch initializes weight and bias matrices uniformly\n",
        "net = nn.Sequential(nn.LazyLinear(8), nn.ReLU(),\n",
        "                    nn.LazyLinear(1))\n",
        "X = torch.rand(size=(2, 4))\n",
        "net(X).shape # [batch size, num of output features]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx5ssskxwswe",
        "outputId": "27292ab9-1521-4a99-a908-c7a99e32a10e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.init module has preset initialization methods\n",
        "# here we are initializing all weight parameters as Gaussian random variables\n",
        "# with standard deviation 0.01, while bias parameters are cleared to 0\n",
        "def init_normal(module):\n",
        "  if type(module) == nn.Linear:\n",
        "    print(\"setting the weights!\")\n",
        "    nn.init.normal_(module.weight, mean=0, std=0.01)\n",
        "    nn.init.zeros_(module.bias)"
      ],
      "metadata": {
        "id": "l0RDnVRkxJ9O"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "zlfG89zoxgcV",
        "outputId": "f7b75340-8047-4f91-f69a-d8da81051784"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.nn.modules.container.Sequential"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.nn.modules.container.Sequential</b><br/>def _wrapped_call_impl(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py</a>A sequential container.\n",
              "\n",
              "Modules will be added to it in the order they are passed in the\n",
              "constructor. Alternatively, an ``OrderedDict`` of modules can be\n",
              "passed in. The ``forward()`` method of ``Sequential`` accepts any\n",
              "input and forwards it to the first module it contains. It then\n",
              "&quot;chains&quot; outputs to inputs sequentially for each subsequent module,\n",
              "finally returning the output of the last module.\n",
              "\n",
              "The value a ``Sequential`` provides over manually calling a sequence\n",
              "of modules is that it allows treating the whole container as a\n",
              "single module, such that performing a transformation on the\n",
              "``Sequential`` applies to each of the modules it stores (which are\n",
              "each a registered submodule of the ``Sequential``).\n",
              "\n",
              "What&#x27;s the difference between a ``Sequential`` and a\n",
              ":class:`torch.nn.ModuleList`? A ``ModuleList`` is exactly what it\n",
              "sounds like--a list for storing ``Module`` s! On the other hand,\n",
              "the layers in a ``Sequential`` are connected in a cascading way.\n",
              "\n",
              "Example::\n",
              "\n",
              "    # Using Sequential to create a small model. When `model` is run,\n",
              "    # input will first be passed to `Conv2d(1,20,5)`. The output of\n",
              "    # `Conv2d(1,20,5)` will be used as the input to the first\n",
              "    # `ReLU`; the output of the first `ReLU` will become the input\n",
              "    # for `Conv2d(20,64,5)`. Finally, the output of\n",
              "    # `Conv2d(20,64,5)` will be used as input to the second `ReLU`\n",
              "    model = nn.Sequential(\n",
              "              nn.Conv2d(1,20,5),\n",
              "              nn.ReLU(),\n",
              "              nn.Conv2d(20,64,5),\n",
              "              nn.ReLU()\n",
              "            )\n",
              "\n",
              "    # Using Sequential with OrderedDict. This is functionally the\n",
              "    # same as the above code\n",
              "    model = nn.Sequential(OrderedDict([\n",
              "              (&#x27;conv1&#x27;, nn.Conv2d(1,20,5)),\n",
              "              (&#x27;relu1&#x27;, nn.ReLU()),\n",
              "              (&#x27;conv2&#x27;, nn.Conv2d(20,64,5)),\n",
              "              (&#x27;relu2&#x27;, nn.ReLU())\n",
              "            ]))</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 43);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(net) == nn.Linear"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPVqfp7cxoMz",
        "outputId": "c2424029-dd19-40d6-de2e-6bf8254c1761"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.apply(init_normal)\n",
        "net[0].weight.data, net[0].bias.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COwRl3u4xrrh",
        "outputId": "c9755ab6-989b-4857-bca8-b8fa1bba624e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "setting the weights!\n",
            "setting the weights!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.0005, -0.0017,  0.0034,  0.0200],\n",
              "         [-0.0058,  0.0106,  0.0013,  0.0011],\n",
              "         [-0.0220, -0.0092, -0.0226,  0.0016],\n",
              "         [-0.0023, -0.0020,  0.0052,  0.0110],\n",
              "         [-0.0082, -0.0036,  0.0106, -0.0116],\n",
              "         [ 0.0145,  0.0122,  0.0045,  0.0082],\n",
              "         [ 0.0069,  0.0045, -0.0097, -0.0055],\n",
              "         [-0.0024, -0.0158, -0.0190, -0.0052]]),\n",
              " tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can also initialize to a constant value\n",
        "def init_constant(module):\n",
        "  if type(module) == nn.Linear:\n",
        "    print(\"setting the weights!\")\n",
        "    nn.init.constant_(module.weight, 1)\n",
        "    nn.init.zeros_(module.bias)\n",
        "\n",
        "net.apply(init_constant)\n",
        "net[0].weight.data, net[0].bias.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kfc36hzcyK4B",
        "outputId": "aaf598d4-31ad-4267-c0f8-51a9283c67ae"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "setting the weights!\n",
            "setting the weights!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can also apply different initializations to different blocks\n",
        "# also something called the Xavier initializer??\n",
        "def init_xavier(module):\n",
        "  if type(module) == nn.Linear:\n",
        "    nn.init.xavier_uniform_(module.weight)\n",
        "\n",
        "def init_42(module):\n",
        "  if type(module) == nn.Linear:\n",
        "    nn.init.constant_(module.weight, 42)\n",
        "\n",
        "net[0].apply(init_xavier)\n",
        "net[2].apply(init_42)\n",
        "print(net[0].weight.data)\n",
        "print(net[2].weight.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7ETjVc2ynYy",
        "outputId": "7fce6cd9-eafe-4221-b255-d6e10fcb2d2e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0569,  0.1886,  0.1994,  0.1537],\n",
            "        [ 0.6438, -0.1747, -0.2422, -0.2468],\n",
            "        [ 0.3365,  0.5402, -0.6510,  0.2670],\n",
            "        [-0.3514, -0.5031,  0.6726, -0.2203],\n",
            "        [ 0.5402,  0.7013, -0.5386, -0.2538],\n",
            "        [ 0.1620,  0.1076, -0.5887,  0.6259],\n",
            "        [-0.5505, -0.5028, -0.4610, -0.7055],\n",
            "        [ 0.2180,  0.4093, -0.0358, -0.5391]])\n",
            "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to represent this as an initialization function\n",
        "\\begin{split}\\begin{aligned}\n",
        "    w \\sim \\begin{cases}\n",
        "        U(5, 10) & \\textrm{ with probability } \\frac{1}{4} \\\\\n",
        "            0    & \\textrm{ with probability } \\frac{1}{2} \\\\\n",
        "        U(-10, -5) & \\textrm{ with probability } \\frac{1}{4}\n",
        "    \\end{cases}\n",
        "\\end{aligned}\\end{split}"
      ],
      "metadata": {
        "id": "HU7mb-mr1l94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_init(module):\n",
        "  if type(module) == nn.Linear:\n",
        "    print(\"Init\", *[(name, param.shape) for\n",
        "                    name, param in module.named_parameters()][0])\n",
        "    nn.init.uniform_(module.weight, -10, 10)\n",
        "    module.weight.data *= module.weight.data.abs() >= 5\n",
        "\n",
        "net.apply(my_init)\n",
        "net[0].weight[:2]\n",
        "# does this match the distribution of random variable w? double check!!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcCv2V9T1y34",
        "outputId": "d076de56-2627-4da5-a9a4-237618451d24"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init weight torch.Size([8, 4])\n",
            "Init weight torch.Size([1, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  5.8175, -9.7044, -0.0000],\n",
              "        [-7.5696,  0.0000,  8.5682, -9.2032]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we always have the option of setting parameters directly\n",
        "net[0].weight.data[:] += 1\n",
        "net[0].weight.data[0, 0] = 42\n",
        "net[0].weight.data\n",
        "# keep running, it keeps adding 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1fsq4H12n4H",
        "outputId": "0d5f1378-ca03-4860-91ce-4f9cda8c3139"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[42.0000, 10.8175, -4.7044,  5.0000],\n",
              "        [-2.5696,  5.0000, 13.5682, -4.2032],\n",
              "        [-2.1281,  5.0000,  5.0000,  5.0000],\n",
              "        [10.1413,  5.0000,  5.0000, -3.9971],\n",
              "        [11.2375, -0.5513,  5.0000, -1.1889],\n",
              "        [11.9251,  5.0000,  5.0000,  5.0000],\n",
              "        [-4.0174,  5.0000,  5.0000,  5.0000],\n",
              "        [ 5.0000, 13.5916,  5.0000,  5.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}